### Readme.txt

#### Usage Instructions:

1. **Download the Dataset:**
   - The `final.csv` file, located in the `Dataset` folder, is used for model evaluations.

2. **Install Required Packages:**
   - Download the `requirements.txt` file and use it to install all the necessary packages for the project.
   - Use this command: pip install -r requirements.txt

3. **Run the Jupyter Notebook:**
- Execute the `.ipynb` file located in the `Codes` folder to run the project.

4. **Results and Metric Evaluations:**
- The `Results` folder contains individual metric evaluation files.
- The combined scores for all metrics are stored in the `combined_scores_output.csv` file.



#### File Descriptions:

- **final.csv:** Contains the data used for model evaluations. Located in the `Dataset` folder.
- **requirements.txt:** Contains a list of all required packages for the project.
- **Codes folder:** Contains Jupyter Notebook files and Python scripts for the project.
- **Results folder:** Contains individual metric evaluation files before and after tuning.
- **combined_scores_output.csv:** Contains combined scores for BERT, ROUGE, BLEU, and other metrics before and after tuning.
- **final_Scores.csv:** Contains combined scores for BERT, ROUGE, BLEU, and other metrics after tuning.




#### Running the Project:

1. **Download Data:**
- Obtain the `final.csv` file from the `Dataset` folder.
- for the fine-tune model obtain output_file.csv from the 'Dataset' folder

2. **Install Dependencies:**
- Run the following command to install all required packages.

3. **Run the Jupyter Notebook:**
- Execute the `.ipynb` file in the `Codes` folder to run the project.

4. **View Metric Evaluations:**
- Individual metric evaluations are available in the `Results` folder.
- The combined metric scores are stored in `combined_scores_output.csv` for comparision between before and after.

#### Note:
- Ensure that the necessary data files are in the correct folders before running the code.
- Check the results.md file in Results folder for the final result.


Thank you!


